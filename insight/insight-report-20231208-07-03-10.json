{"amount_correct": 3, "percentage_score": 15, "report_time": "2023-12-08 12:03:10", "checks": [{"description": "Ensure that the README.md file exists inside of the root of the GitHub repository", "check": "ConfirmFileExists", "status": true, "path": "./README.md"}, {"description": "Delete the phrase 'Add Your Name Here' and add your own name as an Honor Code pledge in README.md", "check": "MatchFileFragment", "objectives": "LO1", "options": {"fragment": "Add Your Name Here", "count": 0, "exact": true}, "status": false, "path": "./README.md", "diagnostic": "Found 1 fragment(s) in the README.md or the output while expecting exactly 0"}, {"description": "Retype the every word in the Honor Code pledge in README.md", "check": "MatchFileFragment", "objectives": "LO1", "options": {"fragment": "I adhered to the Allegheny College Honor Code while completing this assessment.", "count": 2, "exact": true}, "status": false, "path": "./README.md", "diagnostic": "Found 1 fragment(s) in the README.md or the output while expecting exactly 2"}, {"description": "Ensure that assessment.py file exists in the source/ directory", "check": "ConfirmFileExists", "objectives": "LO1", "status": true, "path": "source/assessment.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for assessment.py", "check": "MatchFileFragment", "objectives": "LO1", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "source/assessment.py", "diagnostic": "Found 20 fragment(s) in the assessment.py or the output while expecting exactly 0"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in assessment.py", "check": "CountMultipleLineComments", "objectives": "LO1", "options": {"language": "Python", "count": 8, "exact": true}, "status": false, "path": "source/assessment.py", "diagnostic": "Found 7 comment(s) in the assessment.py or the output"}, {"description": "Correctly invoke the random.randint function provided by the random package for part two in assessment.py", "check": "MatchFileFragment", "objectives": "LO4", "options": {"fragment": "random.randint(0, 100)", "count": 1, "exact": true}, "status": false, "path": "source/assessment.py", "diagnostic": "Found 0 fragment(s) in the assessment.py or the output while expecting exactly 1"}, {"description": "Provide a type annotation the input and output of part three in assessment.py", "check": "MatchFileFragment", "objectives": "LO4", "options": {"fragment": "def count_columns(records: List[List[str]]) -> int:", "count": 1, "exact": true}, "status": false, "path": "source/assessment.py", "diagnostic": "Found 0 fragment(s) in the assessment.py or the output while expecting exactly 1"}, {"description": "Run a program and confirm the correct number of non-blank lines in the output when running the assessment.py program", "check": "CountCommandOutput", "objectives": "LO1", "options": {"command": "python source/assessment.py", "count": 5, "exact": true}, "status": true}, {"description": "Run the program and confirm the existence of correct output for part one of the assessment", "check": "MatchCommandFragment", "objectives": "LO1", "options": {"command": "python source/assessment.py", "fragment": "100 / 5 / True", "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Run the program and confirm the existence of correct output for part two of the assessment", "check": "MatchCommandFragment", "objectives": "LO1", "options": {"command": "python source/assessment.py", "fragment": "3 / 2 / 2 / 1 / 0 / 5 / True", "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Run the program and confirm the existence of correct output for part three of the assessment", "check": "MatchCommandFragment", "objectives": "LO1", "options": {"command": "python source/assessment.py", "fragment": "4 / 3 / 2 / 1 / 0 / True", "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Run the program and confirm the existence of correct output for part four of the assessment", "check": "MatchCommandFragment", "objectives": "LO1", "options": {"command": "python source/assessment.py", "fragment": "3 / 36 / True / True", "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Run the program and confirm the existence of correct output for part five of the assessment", "check": "MatchCommandFragment", "objectives": "LO1", "options": {"command": "python source/assessment.py", "fragment": "('2', 2) / ('Pharmacist, hospital', 3) / True", "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that the source code follows an industry-standard programming rules using the command 'ruff check'", "objectives": "LO4", "command": "ruff check source/assessment.py", "status": false, "diagnostic": "source/assessment.py:9:1: I001 [*] Import block is un-sorted or un-formatted\n     source/assessment.py:130:5: D103 Missing docstring in public function\n     Found 2 errors.\n     [*] 1 fixable with the `--fix` option."}, {"description": "Ensure that the source code adheres to an industry-standard format using the command 'ruff format'", "objectives": "LO4", "command": "ruff format source/assessment.py --check", "status": false, "diagnostic": "Would reformat: source/assessment.py\n     1 file would be reformatted"}, {"description": "Ensure that the source code has correct type annotations using the command 'mypy'", "objectives": "LO4", "command": "mypy source/assessment.py", "status": false, "diagnostic": "source/assessment.py:138: error: Incompatible return value type (got \"list[list[str]]\", expected \"list[str]\")  [return-value]\n     source/assessment.py:300: error: Need type annotation for \"executed_lines\" (hint: \"executed_lines: List[<type>] = ...\")  [var-annotated]\n     source/assessment.py:366: error: Need type annotation for \"common_dict\" (hint: \"common_dict: Dict[<type>, <type>] = ...\")  [var-annotated]\n     source/assessment.py:391: error: Incompatible types in assignment (expression has type \"str\", variable has type \"int\")  [assignment]\n     source/assessment.py:394: error: Incompatible return value type (got \"tuple[int, str]\", expected \"tuple[str, int]\")  [return-value]\n     Found 5 errors in 1 file (checked 1 source file)"}, {"description": "Ensure that the source code has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "objectives": "LO4", "options": {"command": "symbex -s --fully-typed -f source/assessment.py --count", "fragment": 6, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that the source code has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "objectives": "LO4", "options": {"command": "symbex -s --documented -f source/assessment.py --count", "fragment": 7, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that the source code has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "objectives": "LO4", "options": {"command": "symbex -s --undocumented -f source/assessment.py --count", "fragment": 0, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}]}